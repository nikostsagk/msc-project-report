%% ----------------------------------------------------------------
%% Introduction.tex
%% ---------------------------------------------------------------- 
\chapter{Introduction} \label{Chapter:Introduction}
World population is expected to reach 9 billion by the middle of this century. Food production due to climatic change and land restrictions among other factors does not follow this increasing rate (\cite{godfray2010food}). According to \cite{mcguire2015fao}, the rate of undernourished population from 1990 to 2014 was declining (784 million people were undernourished in 2015) and since 2014 is on the rise again (820 million) making apparent the need for securing food. Automation in farms can lower the cost of production and help growers maximise fields' potential, making food accessible to everyone. National Research \cite{NAP5491} defined precision agriculture as a management strategy, which aims to expedite food production by developing decision making and other support systems to help farmers facilitate efficient utilisation of their resources by making use of data gathered with information technologies' techniques. The results of efficient farming, apart from the gains in crop production, can be measured also in terms of invested resources such as labourers, total amounts of water and fertiliser used, thus also reduces the environmental footprint (\cite{zhang2012application}). This thesis, aims to investigate the task of apple detection, in the context of general fruit detection which is a groundwork to robotic harvesting.

\section{Motivation}
Fruit counting is a manual process done to estimate crop production and create accurate yield mappings. Usually, it is being done in large orchards under extreme heat and humid conditions making it a high intensive and time consuming labour task. A common farmers' practice to levitate this, is to count the fruit in a small patch of the orchard and then generalise (\cite{bargoti2017fruit}), thus leading in inaccurate results. Other factors such as occlusion by foliage, other fruits or sunlight contribute to inaccuracy as well. Therefore, the development of an algorithm that can adequately localise and count fruits in an image is necessary to levitate growers from this task by bringing closer robotic harvesting in agriculture. In addition, accurate detection and counting algorithms can serve also in orchard monitoring and yield mapping. by giving continuous measurements about crop production, and anticipating pests and diseases.

\section{Problem Formulation and Objectives}
The aim of this thesis is to investigate through the deployment of a deep learning based object detector framework, how accurately apples can be detected on images under various illuminations and occlusions. Specifically, this project aims to answer the following research question:

\begin{quote}
\centering 
\textit{"How accurately can RetinaNet detect and count the apples on a given RGB dataset taken by monocular cameras?"}
\end{quote}

The contribution to fundamental scientific knowledge in perspective of applications can be achieved within the objectives of the project which are summarised below:

\begin{itemize}
\item \textbf{Deploying and training RetinaNet on the VGG architecture to improve upon the state-of-the-art results.} VGG architecture (\cite{simonyan2014very}) is an architecture based on blocks with increasing receptive field made by stacking $3\times3$ convolutional filters which preserve feature maps' spatial size. This philosophy enables further exploration in lighter models by pruning the main convolutional layers while keeping outputs' size fixed.  
\item \textbf{Identify through systematic experiments the relation between accuracy and the size of the training set.} Deep learning requires large datasets to achieve high performances and generalisations, but labelling process is a laborious and tedious task. A huge dataset is in contrast with the motivation of the problem, which is to exempt labourers from doing this task.
\item \textbf{Identify the causes that limit model's performance.} Apple detection has been tackled with several algorithms on different datasets, thus making comparisons between them impossible. The dataset used in this project, presented through the work of \cite{bargoti2017deep}, has also been used in the work of \cite{liang2018apple}. This dataset has been used many times for fruit detection, but strictly for apple detection through a deep learning approach only by those yielding similar results. This finding raises questions around dataset's structure and the factors that limit models' performance.

\end{itemize}

Pre-trained object detectors are already being used thoroughly for agricultural purposes, especially in fruit detection yielding the state-of-the-art results. Faster - RCNN (\cite{ren2015faster}) was the most widely used detector due to its very high mean average precision (mAP) in the general datasets PASCAL-VOC (\cite{everingham2010pascal}) and MS-COCO (\cite{lin2014microsoft}) and have been used repeatedly for apple detection (\cite{sa2016deepfruits}, \cite{bargoti2017deep}, \cite{tao2018rapid}) and for other fruits as well. Faster - RCNN was succeeded in accuracy by RetinaNet (\cite{lin2017focal}) and YOLOv3 (\cite{redmon2018yolov3}) recently giving space for even better results. YOLOv3 has already been used for fruit detection by yielding the most recent state-of-the-art results (\cite{tian2019apple}), while RetinaNet has not. 

%\section{Vision in robotic harvesting}
%Autonomous harvesting systems consist of two components: (\cite{widyartono2019harvesting}) i) the harvesting system and ii) the machine vision. Machine vision can be further separated in vision for navigation and vision for fruit detection and localisation (machine vision harvesting). The sensing device that is used most in both cases is a colour CCD camera. Furthermore, deployments can either use monocular cameras or stereo systems. Monocular cameras provide all the advantages a colour camera does, that is colour based segmentation and texture information, but lack of scale estimation if distance from object is not known (\cite{gongal2015sensors}). However, stereo cameras are capable of depth estimation and are less sensitive under various illuminations thus they are preferred (\cite{wang2016localisation}). Such a deployment is more expensive and limits the system from being a real-time detector.

\section{Deep Learning in Agriculture}
Image data acquired from cameras can facilitate deep learning techniques especially, convolutional neural networks (CNN) which require spatial 2D inputs (with a depth channel of arbitrary size). \cite{krizhevsky2012imagenet} success of classifying the ImageNet (\cite{deng2009imagenet}) dataset using convolutional neural networks, drew the attention of the agricultural sector. \cite{kamilaris2018deep} in their recent survey demonstrated the popularity of deep learning in agriculture by gathering 40 research papers that make use of it and outperform pre-existing methods. Fruit counting is the second most popular area (after weed identification) and 37 out of these 40 papers were published after 2015. 

\section{Advantages of Deep Learning}
CNNs' success is highlighted by the fact that the need for handcrafted features is getting dismissed. Feature engineering is a time consuming task and not always obvious, since it requires manual knowledge and effort. \cite{bargoti2016image} approached apple detection in images using a multilayer perceptron (MLP) where images were fed along with some metadata such as sun incidence angle, position within farm tree type etc. The gain in performance from metadata was decreasing as the training instances were increasing. Furthermore, deep learning models tend to generalise well with large datasets under different types of illumination and occlusions. For example, \cite{rahnemoonfar2017deep} deployed and trained a model entirely with synthetic data while tested it on real samples, for tomato counting with an accuracy of $91\%$. \cite{chen2017counting} built a fruit counting model trained on challenging datasets with high level of occlusions, uncontrolled illuminations and high similarity between fruit colour and foliage. Both models achieved good generalisation and were robust in occlusion, light conditions and other variations. Training time in Deep Learning models comparing classic approaches is larger (e.g versus a random forest). However, this is relatively vague since the time a model needs relies on resources,  labelling efforts, time spent on optimisation depth of the model etc. A CNN compared with a support vector machine (SVM) is slower to train but there is a huge gain in inference time.

\section{Disadvantages of Deep Learning}
However, it is worth mentioning some of their drawbacks regarding their training and their results. Very deep models need large datasets to converge, and even acquiring sufficient dataset size, there should be enough variance among the samples in order to prevent the model from learning spurious rules to achieve good generalisation. A CNN will not learn anything beyond the expressiveness of the dataset. Data augmentation techniques (artificially increasing the dataset through label preserving transformations) are used in most cases, but there is a generalisation only in a certain extent. Most state-of-the-art deep learning models lack of generalising to other datasets making impossible to compare their results with other methods. Label preserving techniques such as data augmentation are used almost always in training to enlarge the dataset, but there is a generalisation only in a certain extent.  Regarding computational resources, CNNs exploit parallel computing maintained by commercial graphic cards (GPU) accelerating training time on the one hand, but require sufficient GPU memory on the other.


 
 
%\dots
%
%\tref{Table:tabex} illustrates the results of my work.
%\begin{table}[!htb]
%  \centering
%  \begin{tabular}{cc}
%  \toprule
%  \textbf{Training Error} & \textbf{Testing Error}\\
%  \midrule
%  0 & $\infty$\\
%  \bottomrule
%  \end{tabular}
%  \caption{The Results}
%  \label{Table:tabex}
%\end{table}
%
%\fref{Figure:figex} shows why this is the case.
%\begin{figure}[!htb]
%  \centering
%  \includegraphics[width=8cm]{figure}
%  \caption{A colourful picture.}
%  \label{Figure:figex}
%\end{figure}
%
%This page shows you a subfigure example in \fref{Figure:figsubex}.
%\begin{figure}[!htb]
%  \centering
%  \subfigure[The left caption]{
%    \includegraphics[width=4.2cm]{figure}
%    \label{Figure:figsubex:left}
%  }
%  \subfigure[The right caption]{
%    \includegraphics[width=4.2cm]{figure}
%    \label{Figure:figsubex:right}
%  }
%  \caption{A doubly colourful picture.}
%  \label{Figure:figsubex}
%\end{figure}
